{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c47077",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a52d41",
   "metadata": {
    "papermill": {
     "duration": 0.013884,
     "end_time": "2026-02-04T22:36:55.329886",
     "exception": false,
     "start_time": "2026-02-04T22:36:55.316002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deep Learning for Activity Recognition\n",
    "\n",
    "This notebook trains and evaluates deep learning models:\n",
    "- LSTM (Long Short-Term Memory)\n",
    "- 1D-CNN (Convolutional Neural Network)\n",
    "- MLP (Multi-Layer Perceptron) baseline\n",
    "\n",
    "We compare with classical ML results from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bed4c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T22:36:55.344957Z",
     "iopub.status.busy": "2026-02-04T22:36:55.344700Z",
     "iopub.status.idle": "2026-02-04T22:36:57.675740Z",
     "shell.execute_reply": "2026-02-04T22:36:57.675184Z"
    },
    "papermill": {
     "duration": 2.338771,
     "end_time": "2026-02-04T22:36:57.676335",
     "exception": false,
     "start_time": "2026-02-04T22:36:55.337564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sessions/zen-jolly-cori/.local/lib/python3.10/site-packages/pandera/_pandas_deprecated.py:157: FutureWarning: Importing pandas-specific classes and functions from the\n",
      "top-level pandera module will be **removed in a future version of pandera**.\n",
      "If you're using pandera to validate pandas objects, we highly recommend updating\n",
      "your import:\n",
      "\n",
      "```\n",
      "# old import\n",
      "import pandera as pa\n",
      "\n",
      "# new import\n",
      "import pandera.pandas as pa\n",
      "```\n",
      "\n",
      "If you're using pandera to validate objects from other compatible libraries\n",
      "like pyspark or polars, see the supported libraries section of the documentation\n",
      "for more information on how to import pandera:\n",
      "\n",
      "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
      "\n",
      "To disable this warning, set the environment variable:\n",
      "\n",
      "```\n",
      "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
      "```\n",
      "\n",
      "  warnings.warn(_future_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path(\"../src\").resolve()))\n",
    "\n",
    "from fittrack.data.ingestion import HARDataLoader, ACTIVITY_LABELS\n",
    "from fittrack.data.preprocessing import create_train_val_test_split\n",
    "from fittrack.models.data_loaders import (\n",
    "    create_data_loaders,\n",
    "    get_device,\n",
    "    DataModule,\n",
    "    reshape_for_sequence_model,\n",
    ")\n",
    "from fittrack.models.deep_learning import (\n",
    "    ActivityLSTM,\n",
    "    ActivityCNN,\n",
    "    HARClassifier,\n",
    "    TrainingConfig,\n",
    "    train_model,\n",
    "    predict,\n",
    "    create_model,\n",
    ")\n",
    "from fittrack.models.evaluation import (\n",
    "    compute_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_model_comparison,\n",
    "    ModelEvaluator,\n",
    ")\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "FIGURES_DIR = Path(\"../docs/figures\")\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check device\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465285a",
   "metadata": {
    "papermill": {
     "duration": 0.003074,
     "end_time": "2026-02-04T22:36:57.683379",
     "exception": false,
     "start_time": "2026-02-04T22:36:57.680305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d049c8b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T22:36:57.689627Z",
     "iopub.status.busy": "2026-02-04T22:36:57.689444Z",
     "iopub.status.idle": "2026-02-04T22:36:58.698877Z",
     "shell.execute_reply": "2026-02-04T22:36:58.697868Z"
    },
    "papermill": {
     "duration": 1.013033,
     "end_time": "2026-02-04T22:36:58.699215",
     "exception": false,
     "start_time": "2026-02-04T22:36:57.686182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 7352\n",
      "Test samples: 2947\n",
      "Features: 561\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "loader = HARDataLoader()\n",
    "train_data, test_data = loader.load_all()\n",
    "\n",
    "print(f\"Training samples: {train_data.n_samples}\")\n",
    "print(f\"Test samples: {test_data.n_samples}\")\n",
    "print(f\"Features: {train_data.n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ff004",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf614bc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T22:36:58.706603Z",
     "iopub.status.busy": "2026-02-04T22:36:58.706462Z",
     "iopub.status.idle": "2026-02-04T22:36:58.845033Z",
     "shell.execute_reply": "2026-02-04T22:36:58.844376Z"
    },
    "papermill": {
     "duration": 0.142742,
     "end_time": "2026-02-04T22:36:58.845588",
     "exception": true,
     "start_time": "2026-02-04T22:36:58.702846",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got 0.0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create train/val split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_train_val_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Prepare test set\u001b[39;00m\n\u001b[1;32m     11\u001b[0m X_test \u001b[38;5;241m=\u001b[39m split\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mtransform(test_data\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/mnt/Garmin/fittrack-ml/src/fittrack/data/preprocessing.py:193\u001b[0m, in \u001b[0;36mcreate_train_val_test_split\u001b[0;34m(X, y, val_size, test_size, random_state, stratify, normalize)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# First split: train+val vs test\u001b[39;00m\n\u001b[1;32m    191\u001b[0m stratify_split \u001b[38;5;241m=\u001b[39m y_encoded \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m X_trainval, X_test, y_trainval, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Second split: train vs val\u001b[39;00m\n\u001b[1;32m    202\u001b[0m val_ratio \u001b[38;5;241m=\u001b[39m val_size \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m test_size)  \u001b[38;5;66;03m# Adjust for remaining data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:208\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    206\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 208\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m constraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got 0.0 instead."
     ]
    }
   ],
   "source": [
    "# Create train/val split\n",
    "split = create_train_val_test_split(\n",
    "    train_data.X,\n",
    "    train_data.y,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    normalize=True,\n",
    ")\n",
    "\n",
    "# Prepare test set\n",
    "X_test = split.scaler.transform(test_data.X.values)\n",
    "y_test = split.label_encoder.transform(test_data.y[\"activity\"])\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Train: {len(split.X_train)}\")\n",
    "print(f\"  Validation: {len(split.X_val)}\")\n",
    "print(f\"  Test: {len(X_test)}\")\n",
    "\n",
    "class_names = split.class_names\n",
    "n_classes = split.n_classes\n",
    "n_features = split.n_features\n",
    "print(f\"\\nClasses ({n_classes}): {class_names}\")\n",
    "print(f\"Features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f09919",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 64\n",
    "\n",
    "loaders = create_data_loaders(\n",
    "    split.X_train, split.y_train,\n",
    "    split.X_val, split.y_val,\n",
    "    X_test, y_test,\n",
    "    batch_size=batch_size,\n",
    "    weighted_sampling=True,  # Handle class imbalance\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(loaders['train'])}\")\n",
    "print(f\"Val batches: {len(loaders['val'])}\")\n",
    "print(f\"Test batches: {len(loaders['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35d739",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2. MLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1f1d0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create MLP model\n",
    "mlp_model = HARClassifier(\n",
    "    input_size=n_features,\n",
    "    num_classes=n_classes,\n",
    "    hidden_sizes=[256, 128],\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "print(mlp_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in mlp_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c7eb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training config\n",
    "config = TrainingConfig(\n",
    "    epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    patience=10,\n",
    "    scheduler=\"plateau\",\n",
    ")\n",
    "\n",
    "# Train MLP\n",
    "print(\"Training MLP...\")\n",
    "mlp_history = train_model(\n",
    "    mlp_model,\n",
    "    loaders[\"train\"],\n",
    "    loaders[\"val\"],\n",
    "    config=config,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a64a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(mlp_history.train_losses, label=\"Train Loss\")\n",
    "axes[0].plot(mlp_history.val_losses, label=\"Val Loss\")\n",
    "axes[0].axvline(mlp_history.best_epoch, color='r', linestyle='--', label=f\"Best Epoch ({mlp_history.best_epoch})\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"MLP - Training Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(mlp_history.train_accuracies, label=\"Train Acc\")\n",
    "axes[1].plot(mlp_history.val_accuracies, label=\"Val Acc\")\n",
    "axes[1].axvline(mlp_history.best_epoch, color='r', linestyle='--')\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"MLP - Training Accuracy\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"mlp_training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {max(mlp_history.val_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41be3e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. LSTM Model\n",
    "\n",
    "For LSTM, we reshape the features to treat them as a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfdff4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape data for sequence model\n",
    "# Treat the 561 features as a sequence of length 561 with 1 channel\n",
    "# (In a real scenario with raw sensor data, you'd have time x channels)\n",
    "\n",
    "seq_length = n_features\n",
    "n_channels = 1\n",
    "\n",
    "X_train_seq = reshape_for_sequence_model(split.X_train, seq_length, n_channels)\n",
    "X_val_seq = reshape_for_sequence_model(split.X_val, seq_length, n_channels)\n",
    "X_test_seq = reshape_for_sequence_model(X_test, seq_length, n_channels)\n",
    "\n",
    "print(f\"Sequence shape: {X_train_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc7247",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create sequence data loaders\n",
    "seq_loaders = create_data_loaders(\n",
    "    X_train_seq, split.y_train,\n",
    "    X_val_seq, split.y_val,\n",
    "    X_test_seq, y_test,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda251d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "lstm_model = ActivityLSTM(\n",
    "    input_size=n_channels,\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    num_classes=n_classes,\n",
    "    dropout=0.3,\n",
    "    bidirectional=True,\n",
    ")\n",
    "\n",
    "print(lstm_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387f9e3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train LSTM\n",
    "print(\"Training LSTM...\")\n",
    "lstm_config = TrainingConfig(\n",
    "    epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    patience=10,\n",
    "    gradient_clip=1.0,\n",
    ")\n",
    "\n",
    "lstm_history = train_model(\n",
    "    lstm_model,\n",
    "    seq_loaders[\"train\"],\n",
    "    seq_loaders[\"val\"],\n",
    "    config=lstm_config,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6524893",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot LSTM training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(lstm_history.train_losses, label=\"Train Loss\")\n",
    "axes[0].plot(lstm_history.val_losses, label=\"Val Loss\")\n",
    "axes[0].axvline(lstm_history.best_epoch, color='r', linestyle='--', label=f\"Best Epoch ({lstm_history.best_epoch})\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"LSTM - Training Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(lstm_history.train_accuracies, label=\"Train Acc\")\n",
    "axes[1].plot(lstm_history.val_accuracies, label=\"Val Acc\")\n",
    "axes[1].axvline(lstm_history.best_epoch, color='r', linestyle='--')\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"LSTM - Training Accuracy\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"lstm_training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {max(lstm_history.val_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f1ab3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. 1D-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b6a52",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "cnn_model = ActivityCNN(\n",
    "    in_channels=n_channels,\n",
    "    num_classes=n_classes,\n",
    "    seq_length=seq_length,\n",
    "    channels=[32, 64, 128],\n",
    "    kernel_sizes=[7, 5, 3],\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "print(cnn_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c683b79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "print(\"Training CNN...\")\n",
    "cnn_config = TrainingConfig(\n",
    "    epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    patience=10,\n",
    ")\n",
    "\n",
    "cnn_history = train_model(\n",
    "    cnn_model,\n",
    "    seq_loaders[\"train\"],\n",
    "    seq_loaders[\"val\"],\n",
    "    config=cnn_config,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a4ebe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot CNN training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(cnn_history.train_losses, label=\"Train Loss\")\n",
    "axes[0].plot(cnn_history.val_losses, label=\"Val Loss\")\n",
    "axes[0].axvline(cnn_history.best_epoch, color='r', linestyle='--', label=f\"Best Epoch ({cnn_history.best_epoch})\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"CNN - Training Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(cnn_history.train_accuracies, label=\"Train Acc\")\n",
    "axes[1].plot(cnn_history.val_accuracies, label=\"Val Acc\")\n",
    "axes[1].axvline(cnn_history.best_epoch, color='r', linestyle='--')\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"CNN - Training Accuracy\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"cnn_training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {max(cnn_history.val_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5afa7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7229fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate all models on test set\n",
    "evaluator = ModelEvaluator(class_names=class_names, figures_dir=FIGURES_DIR)\n",
    "\n",
    "# MLP (uses flat features)\n",
    "mlp_preds, mlp_probs = predict(mlp_model, loaders[\"test\"], device, return_probs=True)\n",
    "mlp_metrics = compute_metrics(y_test, mlp_preds, mlp_probs, class_names)\n",
    "\n",
    "# LSTM (uses sequence features)\n",
    "lstm_preds, lstm_probs = predict(lstm_model, seq_loaders[\"test\"], device, return_probs=True)\n",
    "lstm_metrics = compute_metrics(y_test, lstm_preds, lstm_probs, class_names)\n",
    "\n",
    "# CNN (uses sequence features)\n",
    "cnn_preds, cnn_probs = predict(cnn_model, seq_loaders[\"test\"], device, return_probs=True)\n",
    "cnn_metrics = compute_metrics(y_test, cnn_preds, cnn_probs, class_names)\n",
    "\n",
    "print(\"Test Set Results:\")\n",
    "print(f\"\\nMLP:\")\n",
    "print(mlp_metrics)\n",
    "print(f\"\\nLSTM:\")\n",
    "print(lstm_metrics)\n",
    "print(f\"\\nCNN:\")\n",
    "print(cnn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e00b3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model comparison plot\n",
    "plot_model_comparison(\n",
    "    {\"MLP\": mlp_metrics, \"LSTM\": lstm_metrics, \"CNN\": cnn_metrics},\n",
    "    metric_names=[\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\"],\n",
    "    title=\"Deep Learning Model Comparison\",\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / \"deep_learning_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f62d2f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, (name, metrics) in zip(axes, [(\"MLP\", mlp_metrics), (\"LSTM\", lstm_metrics), (\"CNN\", cnn_metrics)]):\n",
    "    plt.sca(ax)\n",
    "    plot_confusion_matrix(\n",
    "        metrics.confusion_matrix,\n",
    "        class_names,\n",
    "        title=f\"{name} - Confusion Matrix\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"deep_learning_confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb94877",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Training Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eea6f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Validation Loss\n",
    "axes[0].plot(mlp_history.val_losses, label=\"MLP\")\n",
    "axes[0].plot(lstm_history.val_losses, label=\"LSTM\")\n",
    "axes[0].plot(cnn_history.val_losses, label=\"CNN\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Validation Loss\")\n",
    "axes[0].set_title(\"Validation Loss Comparison\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Validation Accuracy\n",
    "axes[1].plot(mlp_history.val_accuracies, label=\"MLP\")\n",
    "axes[1].plot(lstm_history.val_accuracies, label=\"LSTM\")\n",
    "axes[1].plot(cnn_history.val_accuracies, label=\"CNN\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Validation Accuracy\")\n",
    "axes[1].set_title(\"Validation Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / \"training_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c4948",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025f58f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary_data = {\n",
    "    \"Model\": [\"MLP\", \"LSTM\", \"CNN\"],\n",
    "    \"Accuracy\": [mlp_metrics.accuracy, lstm_metrics.accuracy, cnn_metrics.accuracy],\n",
    "    \"F1 (Macro)\": [mlp_metrics.f1_macro, lstm_metrics.f1_macro, cnn_metrics.f1_macro],\n",
    "    \"Precision\": [mlp_metrics.precision_macro, lstm_metrics.precision_macro, cnn_metrics.precision_macro],\n",
    "    \"Recall\": [mlp_metrics.recall_macro, lstm_metrics.recall_macro, cnn_metrics.recall_macro],\n",
    "    \"Parameters\": [\n",
    "        sum(p.numel() for p in mlp_model.parameters()),\n",
    "        sum(p.numel() for p in lstm_model.parameters()),\n",
    "        sum(p.numel() for p in cnn_model.parameters()),\n",
    "    ],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.round(4)\n",
    "print(\"\\nModel Summary:\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bcc21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_model_name = summary_df.loc[summary_df[\"F1 (Macro)\"].idxmax(), \"Model\"]\n",
    "best_f1 = summary_df[\"F1 (Macro)\"].max()\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"BEST DEEP LEARNING MODEL: {best_model_name}\")\n",
    "print(f\"F1 Score (Macro): {best_f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da033834",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Key Findings\n",
    "\n",
    "1. **MLP** serves as a strong baseline for pre-computed features\n",
    "2. **LSTM** can capture sequential patterns in the feature sequence\n",
    "3. **CNN** learns local patterns effectively through convolutions\n",
    "4. The UCI HAR features are already highly engineered, so deep learning doesn't always outperform classical ML\n",
    "5. With raw sensor data (not pre-computed features), LSTM/CNN would show larger improvements\n",
    "\n",
    "### Next Steps\n",
    "- Implement MLflow tracking for experiment management\n",
    "- Set up A/B testing framework for model comparison\n",
    "- Deploy the best model as a REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23285218",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "models_dir = Path(\"../models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Determine best model and save\n",
    "if best_model_name == \"MLP\":\n",
    "    best_model = mlp_model\n",
    "elif best_model_name == \"LSTM\":\n",
    "    best_model = lstm_model\n",
    "else:\n",
    "    best_model = cnn_model\n",
    "\n",
    "torch.save(best_model.state_dict(), models_dir / f\"best_deep_learning_{best_model_name.lower()}.pt\")\n",
    "print(f\"Saved best model to {models_dir / f'best_deep_learning_{best_model_name.lower()}.pt'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.868969,
   "end_time": "2026-02-04T22:36:59.487933",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/04_deep_learning.ipynb",
   "output_path": "notebooks/04_deep_learning.ipynb",
   "parameters": {},
   "start_time": "2026-02-04T22:36:54.618964",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}